{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FVDR5vm4t0eo"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import re\n",
        "\n",
        "# Initialize the Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the model and tokenizer\n",
        "access_token = \"your key haha\"  # Replace with your actual token\n",
        "model = AutoModelForCausalLM.from_pretrained(\"./gemma_activity_classifier\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-9b\", token=access_token)\n",
        "\n",
        "# Load the label encoder\n",
        "label_encoder = joblib.load('./label_encoder.joblib')\n",
        "\n",
        "# Load your emissions data\n",
        "emissions_data = pd.read_excel(\"activity.xlsx\")  # Adjust path if necessary\n",
        "\n",
        "def get_emission_values(year, location, use_case, category, unit_type):\n",
        "    filtered_data = emissions_data[\n",
        "        (emissions_data['YEAR'] == year) &\n",
        "        (emissions_data['REGION'] == location) &\n",
        "        (emissions_data['POTENTIAL_USE_CASES'].str.contains(use_case, na=False)) &\n",
        "        (emissions_data['CATEGORY'] == category) &\n",
        "        (emissions_data['UNIT_TYPE'] == unit_type)\n",
        "    ]\n",
        "\n",
        "    if not filtered_data.empty:\n",
        "        return {\n",
        "            'activity': filtered_data['ACTIVITY'].values[0],\n",
        "            'CO2e': extract_co2e(filtered_data['EMISSION_FACTORS'].values[0]),\n",
        "            'CH4e': extract_ch4e(filtered_data['EMISSION_FACTORS'].values[0])\n",
        "        }\n",
        "    return None\n",
        "\n",
        "def extract_co2e(emission_factors):\n",
        "    co2e_match = re.search(r'CO2e([\\d.]+)kg', emission_factors)\n",
        "    return float(co2e_match.group(1)) if co2e_match else None\n",
        "\n",
        "def extract_ch4e(emission_factors):\n",
        "    ch4e_match = re.search(r'CH4e([\\d.]+)kg', emission_factors)\n",
        "    return float(ch4e_match.group(1)) if ch4e_match else None\n",
        "\n",
        "def predict_activity(use_case):\n",
        "    input_ids = tokenizer(f\"Use case: {use_case}\\nActivity:\", return_tensors=\"pt\").input_ids\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids)\n",
        "\n",
        "    predicted_activity = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    decoded_activity = predicted_activity.split(\"Activity:\")[-1].strip()\n",
        "    activity_label = label_encoder.inverse_transform([decoded_activity])[0]\n",
        "\n",
        "    return activity_label\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def home():\n",
        "    return '''<h1>Emission Activity Prediction</h1>\n",
        "              <p>Enter parameters to predict activity and emission values.</p>\n",
        "              <form action=\"/predict\" method=\"POST\">\n",
        "                Year: <input type=\"text\" name=\"year\"><br>\n",
        "                Location: <input type=\"text\" name=\"location\"><br>\n",
        "                Use Case: <input type=\"text\" name=\"use_case\"><br>\n",
        "                Category: <input type=\"text\" name=\"category\"><br>\n",
        "                Unit Type: <input type=\"text\" name=\"unit_type\"><br>\n",
        "                <input type=\"submit\" value=\"Submit\">\n",
        "              </form>'''\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    year = int(request.form['year'])\n",
        "    location = request.form['location']\n",
        "    use_case = request.form['use_case']\n",
        "    category = request.form['category']\n",
        "    unit_type = request.form['unit_type']\n",
        "\n",
        "    emission_values = get_emission_values(year, location, use_case, category, unit_type)\n",
        "\n",
        "    if emission_values:\n",
        "        return jsonify({\n",
        "            'activity': emission_values['activity'],\n",
        "            'CO2e': emission_values['CO2e'],\n",
        "            'CH4e': emission_values['CH4e']\n",
        "        })\n",
        "    else:\n",
        "        return jsonify({'error': 'No matching activity found.'})\n",
        "\n",
        "# Start ngrok and get the public URL\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "def clean_prediction(text):\n",
        "    # Remove repetitions\n",
        "    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)\n",
        "    # Remove 'sector:', 'energy:', etc.\n",
        "    text = re.sub(r'\\w+:', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text.strip().lower()\n",
        "\n",
        "def flexible_test_model_with_training_data(model, tokenizer, label_encoder, df, max_length=50, num_beams=5):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "    all_samples = []\n",
        "\n",
        "    progress_bar = tqdm(total=len(df), desc=\"Testing\")\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        use_case = row['POTENTIAL_USE_CASES']\n",
        "        true_label = row['activity_label']\n",
        "        true_activity = label_encoder.inverse_transform([true_label])[0]\n",
        "\n",
        "        input_text = f\"Use case: {use_case}\\nActivity:\"\n",
        "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                outputs = model.generate(\n",
        "                    input_ids,\n",
        "                    max_length=max_length,\n",
        "                    num_beams=num_beams,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            predicted_activity = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            decoded_activity = predicted_activity.split(\"Activity:\")[-1]\n",
        "            cleaned_activity = clean_prediction(decoded_activity)\n",
        "\n",
        "            # Try to find the closest match in the label encoder classes\n",
        "            possible_labels = label_encoder.classes_\n",
        "            closest_match = min(possible_labels, key=lambda x: len(set(x.split()) & set(cleaned_activity.split())))\n",
        "\n",
        "            predicted_label = label_encoder.transform([closest_match])[0]\n",
        "            all_predictions.append(predicted_label)\n",
        "            all_true_labels.append(true_label)\n",
        "\n",
        "            all_samples.append({\n",
        "                'use_case': use_case,\n",
        "                'true_activity': true_activity,\n",
        "                'raw_prediction': decoded_activity,\n",
        "                'cleaned_prediction': cleaned_activity,\n",
        "                'matched_prediction': closest_match,\n",
        "                'correct': true_activity == closest_match\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing sample: {e}\")\n",
        "            all_samples.append({\n",
        "                'use_case': use_case,\n",
        "                'true_activity': true_activity,\n",
        "                'raw_prediction': 'Error in generation',\n",
        "                'cleaned_prediction': 'Error',\n",
        "                'matched_prediction': 'Error',\n",
        "                'correct': False\n",
        "            })\n",
        "\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(all_true_labels, all_predictions)\n",
        "    print(f\"Model Accuracy on Training Data: {accuracy:.4f}\")\n",
        "    print(f\"Total samples: {len(df)}\")\n",
        "    print(f\"Processed samples: {len(all_predictions)}\")\n",
        "\n",
        "    # Generate a detailed classification report\n",
        "    class_names = label_encoder.classes_\n",
        "    report = classification_report(all_true_labels, all_predictions, target_names=class_names)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Save all samples to CSV\n",
        "    samples_df = pd.DataFrame(all_samples)\n",
        "    samples_df.to_csv('prediction_results.csv', index=False)\n",
        "    print(\"All prediction results saved to 'prediction_results.csv'\")\n",
        "\n",
        "    return accuracy, samples_df\n",
        "\n",
        "# Usage example:\n",
        "accuracy, results_df = flexible_test_model_with_training_data(model, tokenizer, label_encoder, df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6NU1PekF1X5F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}